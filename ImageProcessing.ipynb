{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90e3e5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\IT\\\\GITHUB\\\\Hutech-AI-Challenge\\\\PatternFinding'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "root = os.getcwd()\n",
    "root "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75910aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 10 01:29:24 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650 Ti   WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   52C    P8              4W /   50W |    1435MiB /   4096MiB |     19%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2380    C+G   ... Access Service\\ePowerButton_NB.exe      N/A      |\n",
      "|    0   N/A  N/A      2684    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A      3432    C+G   ...25.3.2\\plugins\\capture\\ZaloCall.exe      N/A      |\n",
      "|    0   N/A  N/A      9296    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "|    0   N/A  N/A      9428    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     11924    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     12764    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12772    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12852    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14512    C+G   ...\\Programs\\Zalo\\Zalo-25.3.2\\Zalo.exe      N/A      |\n",
      "|    0   N/A  N/A     16180    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16484    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     20424    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     20896      C   D:\\Anaconda\\envs\\Research\\python.exe        N/A      |\n",
      "|    0   N/A  N/A     21460    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f32ab80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe160ee",
   "metadata": {},
   "source": [
    "# Pytorch DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae20c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python pillow torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d448bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def apply_clahe_pil(image_pil):\n",
    "    \"\"\"Apply CLAHE để normalize độ tương phản của ảnh đầu vào.\n",
    "    Args:\n",
    "        image_pil (PIL.Image): Ảnh đầu vào dưới dạng đối tượng PIL.\"\"\"\n",
    "    img = np.array(image_pil)\n",
    "\n",
    "    # Chuyển sang LAB\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Áp dụng CLAHE lên kênh L\n",
    "    clahe = cv2.createCLAHE(clipLimit=0.5, tileGridSize=(4, 4))\n",
    "    cl = clahe.apply(l)\n",
    "\n",
    "    # Hợp lại và chuyển về RGB\n",
    "    merged = cv2.merge((cl, a, b))\n",
    "    final = cv2.cvtColor(merged, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    return Image.fromarray(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "121ed899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "class CLAHETransform:\n",
    "    def __call__(self, img):\n",
    "        return apply_clahe_pil(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e2a04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    # CLAHETransform(),                            # (1) Chuẩn hoá tương phản cục bộ\n",
    "    transforms.RandomHorizontalFlip(p=0.5),      # (2) Lật ngang\n",
    "    transforms.RandomVerticalFlip(p=0.2),        # (3) Lật dọc (ít hơn)\n",
    "    transforms.RandomRotation(15),               # (4) Xoay ±15 độ\n",
    "    # transforms.ColorJitter(brightness=0.2,       # (5) Điều chỉnh độ sáng\n",
    "    #                        contrast=0.2,\n",
    "    #                        saturation=0.2,\n",
    "    #                        hue=0.02),\n",
    "    transforms.RandomAffine(degrees=0,\n",
    "                            translate=(0.1, 0.1),  # (6) Dịch vị trí\n",
    "                            scale=(0.9, 1.1)),     # (7) Zoom in/out nhẹ\n",
    "\n",
    "    transforms.ToTensor(),                        # (8) Chuyển về Tensor\n",
    "    # transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "    transforms.Normalize(mean=[0.4397, 0.3948, 0.3603], std=[0.1841, 0.1777, 0.1702])  #train\n",
    "])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    CLAHETransform(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0def302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = ImageFolder(root='D:\\\\IT\\\\GITHUB\\\\Hutech-AI-Challenge\\\\data\\\\train', transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee6e3c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 test images\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class FlatImageDataset(Dataset):\n",
    "    \"\"\"Dataset for loading images from a flat directory structure (no class subdirectories).\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = [\n",
    "            os.path.join(root_dir, filename) \n",
    "            for filename in os.listdir(root_dir) \n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))\n",
    "        ]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')  # Ensure RGB format\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Return image with a dummy label (0)\n",
    "        return image, 0\n",
    "        \n",
    "# Replace the test dataset and loader\n",
    "test_path = \"D:\\\\IT\\\\GITHUB\\\\Hutech-AI-Challenge\\\\data\\\\test\"\n",
    "test_dataset = FlatImageDataset(root_dir=test_path, transform=val_transform)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=False, \n",
    "    num_workers=0,  # Start with 0 to avoid worker errors\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(test_dataset)} test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "76d13c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(test_loader.dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a2bc7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\Research\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\Research\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Loss: 0.9480\n",
      "Epoch [2/10] - Loss: 0.5162\n",
      "Epoch [3/10] - Loss: 0.3277\n",
      "Epoch [4/10] - Loss: 0.2908\n",
      "Epoch [5/10] - Loss: 0.1802\n",
      "Epoch [6/10] - Loss: 0.1773\n",
      "Epoch [7/10] - Loss: 0.1396\n",
      "Epoch [8/10] - Loss: 0.1396\n",
      "Epoch [9/10] - Loss: 0.1516\n",
      "Epoch [10/10] - Loss: 0.0999\n"
     ]
    }
   ],
   "source": [
    "# \"Ví dụ về cách train mô hình với Dataloader\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model\n",
    "model = resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 4)  # 4 loại nấm\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss và Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/10] - Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3bbe55a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 2, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 3, 0, 3, 3, 3, 3, 0, 3, 3, 0, 0, 0, 0, 0, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0, 0, 3, 0, 0, 3, 3, 0, 0, 3, 3, 3, 3, 0, 3, 0, 0, 0, 0, 0, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:  # Assuming test_loader doesn't have labels\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "print(f\"Predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test-Time Augmentation - Augment trong lúc test rồi lấy major voting\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Các TTA transforms áp dụng cho mỗi ảnh\n",
    "tta_transforms = [\n",
    "    transforms.Compose([transforms.ToTensor()]),\n",
    "    transforms.Compose([transforms.RandomHorizontalFlip(p=1.0), transforms.ToTensor()]),\n",
    "    transforms.Compose([transforms.RandomRotation(degrees=10), transforms.ToTensor()]),\n",
    "    transforms.Compose([transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)), transforms.ToTensor()])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40832224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict_loader_with_tta(model, dataloader, tta_transforms, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Predicting with TTA\"):\n",
    "            images, _ = batch  # Giả sử test set không có nhãn\n",
    "            batch_preds = []\n",
    "\n",
    "            for t in tta_transforms:\n",
    "                augmented_images = torch.stack([t(transforms.ToPILImage()(img.cpu())) for img in images])\n",
    "                augmented_images = augmented_images.to(device)\n",
    "                outputs = model(augmented_images)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                batch_preds.append(probs)\n",
    "\n",
    "            # Trung bình xác suất qua các phiên bản TTA\n",
    "            avg_preds = torch.mean(torch.stack(batch_preds), dim=0)\n",
    "            pred_labels = torch.argmax(avg_preds, dim=1)\n",
    "            all_preds.extend(pred_labels.cpu().numpy())\n",
    "\n",
    "    return all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d01776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with TTA: 100%|██████████| 7/7 [00:00<00:00,  8.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "test_dataset = FlatImageDataset(root_dir=test_path, transform=val_transform)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=False, \n",
    "    num_workers=0,  # Start with 0 to avoid worker errors\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "# Thiết bị\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Dự đoán có TTA\n",
    "predictions = predict_loader_with_tta(model, test_loader, tta_transforms, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080989a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd58464",
   "metadata": {},
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1838c020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1200 images from D:\\IT\\GITHUB\\Hutech-AI-Challenge\\data\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating statistics: 100%|██████████| 19/19 [00:04<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean: [0.43967322 0.3947982  0.36026132]\n",
      "Train Std: [0.18411897 0.1776691  0.17019545]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean and std for normalization\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def calculate_dataset_statistics(dataset_path, batch_size=64, num_workers=2):\n",
    "    \"\"\"Calculate mean and std of a dataset for normalization.\"\"\"\n",
    "    try:\n",
    "        # Verify path exists\n",
    "        if not os.path.exists(dataset_path):\n",
    "            raise FileNotFoundError(f\"Dataset path not found: {dataset_path}\")\n",
    "            \n",
    "        # Create dataset and loader\n",
    "        dataset = ImageFolder(dataset_path, transform=transforms.ToTensor())\n",
    "        loader = DataLoader(\n",
    "            dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=num_workers,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        \n",
    "        print(f\"Processing {len(dataset)} images from {dataset_path}\")\n",
    "        \n",
    "        # Initialize statistics\n",
    "        mean = 0.0\n",
    "        std = 0.0\n",
    "        nb_samples = 0\n",
    "        \n",
    "        # Process batches with progress bar\n",
    "        for data, _ in tqdm(loader, desc=\"Calculating statistics\"):\n",
    "            batch_samples = data.size(0)\n",
    "            data = data.view(batch_samples, data.size(1), -1)\n",
    "            mean += data.mean(2).sum(0)\n",
    "            std += data.std(2).sum(0)\n",
    "            nb_samples += batch_samples\n",
    "        \n",
    "        # Calculate final statistics\n",
    "        mean /= nb_samples\n",
    "        std /= nb_samples\n",
    "        \n",
    "        return mean.numpy(), std.numpy()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating dataset statistics: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# Calculate for train dataset\n",
    "train_path = \"D:\\\\IT\\\\GITHUB\\\\Hutech-AI-Challenge\\\\data\\\\train\"\n",
    "train_mean, train_std = calculate_dataset_statistics(train_path)\n",
    "print(f\"Train Mean: {train_mean}\")\n",
    "print(f\"Train Std: {train_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a463b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 1200/1200 [00:02<00:00, 513.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "INPUT_FOLDER = \"D:\\\\IT\\\\GITHUB\\\\Hutech-AI-Challenge\\\\data\\\\train\"\n",
    "OUTPUT_FOLDER = \"D:\\\\IT\\\\GITHUB\\\\Hutech-AI-Challenge\\\\data\\\\train_CLAHE\"\n",
    "\n",
    "# Clear output directory if needed\n",
    "if os.path.exists(OUTPUT_FOLDER):\n",
    "    shutil.rmtree(OUTPUT_FOLDER)\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# Get all image files\n",
    "image_files = []\n",
    "for root, _, files in os.walk(INPUT_FOLDER):\n",
    "    for file in files:\n",
    "        if file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            image_files.append((root, file))\n",
    "\n",
    "print(f\"Found {len(image_files)} images to process\")\n",
    "\n",
    "# Process images with progress bar\n",
    "for root, file in tqdm(image_files, desc=\"Processing images\"):\n",
    "    try:\n",
    "        # Get relative path to maintain folder structure\n",
    "        rel_path = os.path.relpath(root, INPUT_FOLDER)\n",
    "        if rel_path != \".\":\n",
    "            output_dir = os.path.join(OUTPUT_FOLDER, rel_path)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "        else:\n",
    "            output_dir = OUTPUT_FOLDER\n",
    "            \n",
    "        # Process image\n",
    "        path = os.path.join(root, file)\n",
    "        image = Image.open(path).convert(\"RGB\")  # Ensure RGB mode\n",
    "        enhanced = apply_clahe(image)\n",
    "        \n",
    "        # Save processed image\n",
    "        save_path = os.path.join(output_dir, file)\n",
    "        enhanced.save(save_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
